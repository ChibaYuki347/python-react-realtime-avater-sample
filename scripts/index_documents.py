#!/usr/bin/env python3
"""
ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’Blob Storageã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€
Azure AI Search ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã¾ã™ã€‚å®šæœŸçš„ãªãƒãƒƒãƒå‡¦ç†ã¨ã—ã¦å®Ÿè¡Œã§ãã¾ã™ã€‚

ä½¿ç”¨ä¾‹:
    python index_documents.py --folder ./data/documents --container rag-documents
    python index_documents.py --folder ./data/documents --index-name my-index --verbose
"""

import argparse
import logging
import sys
import os
from pathlib import Path
from dotenv import load_dotenv
from utils.rag_indexer import RAGIndexer, setup_logging


def main():
    parser = argparse.ArgumentParser(
        description="ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ"
    )
    parser.add_argument(
        "--folder",
        required=True,
        help="ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å¯¾è±¡ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ•ã‚©ãƒ«ãƒ€",
    )
    parser.add_argument(
        "--container",
        default="rag-documents",
        help="Blob Storage ã‚³ãƒ³ãƒ†ãƒŠåï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: rag-documentsï¼‰",
    )
    parser.add_argument(
        "--index-name",
        default="rag-index",
        help="Azure Search ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: rag-indexï¼‰",
    )
    parser.add_argument(
        "--search-endpoint",
        help="Azure Search Service ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆç’°å¢ƒå¤‰æ•°ã§è¨­å®šå¯èƒ½ï¼‰",
    )
    parser.add_argument(
        "--storage-url",
        help="Azure Blob Storage ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ URLï¼ˆç’°å¢ƒå¤‰æ•°ã§è¨­å®šå¯èƒ½ï¼‰",
    )
    parser.add_argument(
        "--use-managed-identity",
        action="store_true",
        default=True,
        help="Managed Identity ã‚’ä½¿ç”¨ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: trueï¼‰",
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="è©³ç´°ãƒ­ã‚°ã‚’å‡ºåŠ›",
    )

    args = parser.parse_args()

    # ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
    setup_logging(verbose=args.verbose)
    logger = logging.getLogger(__name__)

    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿
    load_dotenv()
    search_endpoint = args.search_endpoint or os.getenv("AZURE_SEARCH_SERVICE_ENDPOINT")
    storage_url = args.storage_url or os.getenv("AZURE_STORAGE_ACCOUNT_URL")

    if not search_endpoint:
        logger.error("âŒ ã‚¨ãƒ©ãƒ¼: AZURE_SEARCH_SERVICE_ENDPOINT ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        sys.exit(1)

    if not storage_url:
        logger.error("âŒ ã‚¨ãƒ©ãƒ¼: AZURE_STORAGE_ACCOUNT_URL ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        sys.exit(1)

    # ãƒ•ã‚©ãƒ«ãƒ€ã®å­˜åœ¨ç¢ºèª
    folder_path = Path(args.folder)
    if not folder_path.exists():
        logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.folder}")
        sys.exit(1)

    try:
        logger.info("=" * 60)
        logger.info("ğŸ“„ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
        logger.info("=" * 60)
        logger.info(f"ãƒ•ã‚©ãƒ«ãƒ€: {args.folder}")
        logger.info(f"ã‚³ãƒ³ãƒ†ãƒŠ: {args.container}")
        logger.info(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {args.index_name}")
        logger.info(f"Search ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ: {search_endpoint}")
        logger.info(f"Storage URL: {storage_url}")
        logger.info("")

        # RAG ã‚¤ãƒ³ãƒ‡ã‚¯ã‚µãƒ¼ã‚’åˆæœŸåŒ–
        indexer = RAGIndexer(
            search_service_endpoint=search_endpoint,
            storage_account_url=storage_url,
            use_managed_identity=args.use_managed_identity,
        )

        # ã‚³ãƒ³ãƒ†ãƒŠã‚’ä½œæˆï¼ˆå­˜åœ¨ã—ãªã„å ´åˆã®ã¿ï¼‰
        logger.info("ğŸ“¦ ã‚³ãƒ³ãƒ†ãƒŠã‚’ç¢ºèªãƒ»ä½œæˆä¸­...")
        if not indexer.create_container(args.container):
            logger.error(f"âŒ ã‚³ãƒ³ãƒ†ãƒŠä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {args.container}")
            sys.exit(1)

        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ
        logger.info("ğŸ”¨ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆä¸­...")
        indexer.create_index(args.index_name)

        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        logger.info(f"ğŸ“¤ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...")
        results = indexer.batch_upload_documents(args.container, str(folder_path))

        # çµæœã‚’å‡ºåŠ›
        logger.info("")
        logger.info("=" * 60)
        logger.info("ğŸ“Š å‡¦ç†çµæœ")
        logger.info("=" * 60)
        logger.info(f"âœ“ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æˆåŠŸ: {results['uploaded']} ä»¶")
        logger.info(f"âŒ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {results['failed']} ä»¶")
        logger.info(f"â­ ã‚¹ã‚­ãƒƒãƒ—: {results['skipped']} ä»¶")
        logger.info("=" * 60)

        if results["failed"] > 0:
            logger.warning("âš  ä¸€éƒ¨ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒå¤±æ•—ã—ã¾ã—ãŸ")
            sys.exit(1)

        # Indexer ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚’è‡ªå‹•å®Ÿè¡Œ
        logger.info("")
        logger.info("ğŸ”§ DataSource ã¨ Indexer ã‚’ä½œæˆä¸­...")
        
        # Storage Account åã‚’æŠ½å‡º
        storage_account_name = storage_url.split("//")[1].split(".")[0]
        
        if indexer.create_data_source_and_indexer(
            index_name=args.index_name,
            container_name=args.container,
            storage_account_name=storage_account_name
        ):
            logger.info("")
            logger.info("=" * 60)
            logger.info("âœ… ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            logger.info("=" * 60)
            logger.info("")
            logger.info("ğŸ“Š ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–ã®é€²æ—ã¯ Azure Portal ã§ç¢ºèªã§ãã¾ã™:")
            logger.info(f"   https://portal.azure.com")
            logger.info("")
            logger.info("ğŸ’¡ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†…å®¹ã‚’ç¢ºèª:")
            logger.info(f"   curl 'https://{search_endpoint.split('//')[1]}/indexes/{args.index_name}/docs/\\$count?api-version=2024-07-01' \\")
            logger.info(f"     -H 'Authorization: Bearer $(az account get-access-token --resource https://search.azure.com --query accessToken -o tsv)'")
            logger.info("")
        else:
            logger.error("âŒ DataSource/Indexer ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            sys.exit(1)

    except Exception as e:
        logger.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
