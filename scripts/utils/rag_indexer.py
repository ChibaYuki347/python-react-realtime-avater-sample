"""
Azure RAG ã‚¤ãƒ³ãƒ‡ã‚­ã‚·ãƒ³ã‚°ãƒ»ã‚³ã‚¢ãƒ­ã‚¸ãƒƒã‚¯

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†ã¨Azure AI Searchã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆã®
ã‚³ã‚¢æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚Managed Identityèªè¨¼ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚
"""

import logging
import requests
import json
from typing import Optional
from pathlib import Path
from azure.identity import DefaultAzureCredential
from azure.storage.blob import BlobServiceClient
from azure.search.documents.indexes import SearchIndexClient
from azure.search.documents.indexes.models import (
    SearchIndex,
    SearchField,
    SearchFieldDataType,
    SimpleField,
    SearchableField,
)


logger = logging.getLogger(__name__)


class RAGIndexer:
    """
    RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç®¡ç†ã‚’æ‹…å½“ã™ã‚‹ã‚¯ãƒ©ã‚¹
    
    Managed Identity ã«ã‚ˆã‚‹èªè¨¼ã‚’ä½¿ç”¨ã—ã¦ Azure ãƒªã‚½ãƒ¼ã‚¹ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¾ã™ã€‚
    """

    def __init__(
        self,
        search_service_endpoint: str,
        search_service_key: Optional[str] = None,
        storage_account_url: Optional[str] = None,
        storage_account_key: Optional[str] = None,
        use_managed_identity: bool = True,
    ):
        """
        RAGIndexerã‚’åˆæœŸåŒ–ã—ã¾ã™
        
        Args:
            search_service_endpoint: Azure Search Service ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ URL
            search_service_key: Search Service ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼ï¼ˆMIã‚’ä½¿ã‚ãªã„å ´åˆï¼‰
            storage_account_url: Blob Storage ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ URL
            storage_account_key: Blob Storage ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼ï¼ˆMIã‚’ä½¿ã‚ãªã„å ´åˆï¼‰
            use_managed_identity: Managed Identity ã‚’ä½¿ç”¨ã™ã‚‹ã‹ã©ã†ã‹ï¼ˆæ¨å¥¨: Trueï¼‰
        """
        self.search_service_endpoint = search_service_endpoint
        self.storage_account_url = storage_account_url
        self.use_managed_identity = use_managed_identity
        self.credential = None

        # èªè¨¼æ–¹å¼ã®è¨­å®š
        if use_managed_identity:
            logger.info("âœ“ Managed Identity èªè¨¼ã‚’ä½¿ç”¨ã—ã¾ã™")
            self.credential = DefaultAzureCredential()
        else:
            logger.warning("âš  API ã‚­ãƒ¼èªè¨¼ã‚’ä½¿ç”¨ã—ã¾ã™ï¼ˆæœ¬ç•ªç’°å¢ƒã§ã¯æ¨å¥¨ã•ã‚Œã¾ã›ã‚“ï¼‰")
            self.credential = None

        # Azure Search ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        try:
            if use_managed_identity:
                self.search_index_client = SearchIndexClient(
                    endpoint=search_service_endpoint, credential=self.credential
                )
            else:
                self.search_index_client = SearchIndexClient(
                    endpoint=search_service_endpoint, api_key=search_service_key
                )
            logger.info("âœ“ Search Index Client ãŒåˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ")
        except Exception as e:
            logger.error(f"âŒ Search Index Client åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise

        # Azure Blob Storage ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        try:
            if use_managed_identity and storage_account_url:
                self.blob_service_client = BlobServiceClient(
                    account_url=storage_account_url, credential=self.credential
                )
            elif storage_account_url and storage_account_key:
                self.blob_service_client = BlobServiceClient(
                    account_url=storage_account_url, credential=storage_account_key
                )
            else:
                self.blob_service_client = None
                logger.warning("âš  Blob Storage Client ã¯åˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        except Exception as e:
            logger.error(f"âŒ Blob Storage Client åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def create_container(self, container_name: str) -> bool:
        """
        Blob Storage ã«ã‚³ãƒ³ãƒ†ãƒŠã‚’ä½œæˆã—ã¾ã™ï¼ˆå­˜åœ¨ã—ãªã„å ´åˆã®ã¿ï¼‰
        
        Args:
            container_name: ä½œæˆã™ã‚‹ã‚³ãƒ³ãƒ†ãƒŠå
        
        Returns:
            æˆåŠŸæ™‚: Trueã€å¤±æ•—æ™‚: False
        """
        if not self.blob_service_client:
            logger.error("âŒ Blob Storage Client ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False

        try:
            container_client = self.blob_service_client.get_container_client(
                container_name
            )
            container_client.get_container_properties()
            logger.info(f"âœ“ ã‚³ãƒ³ãƒ†ãƒŠ '{container_name}' ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")
            return True
        except Exception:
            # ã‚³ãƒ³ãƒ†ãƒŠãŒå­˜åœ¨ã—ãªã„ã®ã§ä½œæˆ
            try:
                self.blob_service_client.create_container(container_name)
                logger.info(f"âœ“ ã‚³ãƒ³ãƒ†ãƒŠ '{container_name}' ã‚’ä½œæˆã—ã¾ã—ãŸ")
                return True
            except Exception as e:
                logger.error(f"âŒ ã‚³ãƒ³ãƒ†ãƒŠä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
                return False

    def create_index(self, index_name: str) -> None:
        """
        Azure AI Search ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã¾ã™
        
        Args:
            index_name: ä½œæˆã™ã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®åå‰
        """
        try:
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            try:
                self.search_index_client.get_index(index_name)
                logger.info(f"âœ“ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ '{index_name}' ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")
                return
            except Exception:
                pass

            # æ–°ã—ã„ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å®šç¾©
            fields = [
                SimpleField(name="id", type=SearchFieldDataType.String, key=True),
                SearchableField(
                    name="content",
                    type=SearchFieldDataType.String,
                    analyzer_name="ja.microsoft",
                ),
                SimpleField(
                    name="filename",
                    type=SearchFieldDataType.String,
                    filterable=True,
                    searchable=True,
                ),
                SimpleField(
                    name="metadata_storage_path",
                    type=SearchFieldDataType.String,
                    retrievable=True,
                ),
                SimpleField(
                    name="metadata_storage_name",
                    type=SearchFieldDataType.String,
                    searchable=True,
                    filterable=True,
                ),
            ]

            index = SearchIndex(name=index_name, fields=fields)
            self.search_index_client.create_index(index)
            logger.info(f"âœ“ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ '{index_name}' ãŒä½œæˆã•ã‚Œã¾ã—ãŸ")

        except Exception as e:
            logger.error(f"âŒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def upload_document(
        self,
        container_name: str,
        blob_name: str,
        file_path: str,
    ) -> bool:
        """
        ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’Blob Storageã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™
        
        Args:
            container_name: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å…ˆã‚³ãƒ³ãƒ†ãƒŠå
            blob_name: Blob ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå
            file_path: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        
        Returns:
            ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æˆåŠŸæ™‚: Trueã€å¤±æ•—æ™‚: False
        """
        if not self.blob_service_client:
            logger.error("âŒ Blob Storage Client ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False

        try:
            container_client = self.blob_service_client.get_container_client(
                container_name
            )

            with open(file_path, "rb") as data:
                container_client.upload_blob(blob_name, data, overwrite=True)

            logger.info(f"âœ“ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ '{blob_name}' ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ")
            return True

        except FileNotFoundError:
            logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
            return False
        except Exception as e:
            logger.error(f"âŒ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def batch_upload_documents(
        self, container_name: str, folder_path: str, extensions: list = None
    ) -> dict:
        """
        ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä¸€æ‹¬ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™
        
        Args:
            container_name: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å…ˆã‚³ãƒ³ãƒ†ãƒŠå
            folder_path: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹
            extensions: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯¾è±¡æ‹¡å¼µå­ãƒªã‚¹ãƒˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ['.txt', '.pdf', '.docx']ï¼‰
        
        Returns:
            å‡¦ç†çµæœè¾æ›¸ {"uploaded": æˆåŠŸä»¶æ•°, "failed": å¤±æ•—ä»¶æ•°, "skipped": ã‚¹ã‚­ãƒƒãƒ—ä»¶æ•°}
        """
        if extensions is None:
            extensions = [".txt", ".pdf", ".docx"]

        results = {"uploaded": 0, "failed": 0, "skipped": 0}
        folder = Path(folder_path)

        if not folder.exists():
            logger.error(f"âŒ ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {folder_path}")
            return results

        for file_path in folder.rglob("*"):
            if file_path.is_dir():
                continue

            if file_path.suffix.lower() not in extensions:
                results["skipped"] += 1
                continue

            blob_name = file_path.relative_to(folder).as_posix()
            if self.upload_document(container_name, blob_name, str(file_path)):
                results["uploaded"] += 1
            else:
                results["failed"] += 1

        return results

    def create_data_source_and_indexer(
        self, index_name: str, container_name: str, storage_account_name: str
    ) -> bool:
        """
        Azure Search REST API ã§ DataSource ã¨ Indexer ã‚’ä½œæˆã—ã¾ã™
        
        Args:
            index_name: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å
            container_name: Blob ã‚³ãƒ³ãƒ†ãƒŠå
            storage_account_name: Storage Account å
        
        Returns:
            æˆåŠŸæ™‚: Trueã€å¤±æ•—æ™‚: False
        """
        try:
            # Azure Search ã®ãƒ™ãƒ¼ã‚¹ URL
            search_service_name = self.search_service_endpoint.split("//")[1].split(".")[0]
            api_version = "2024-07-01"
            
            # ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
            token = self.credential.get_token("https://search.azure.com/.default")
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {token.token}"
            }
            
            logger.info("ğŸ”§ DataSource ã‚’ä½œæˆä¸­...")
            
            # DataSource ä½œæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            data_source_url = f"{self.search_service_endpoint}/datasources/blob-documents-source?api-version={api_version}"
            data_source_payload = {
                "name": "blob-documents-source",
                "type": "azureblob",
                "credentials": {
                    "connectionString": f"ResourceId=/subscriptions/{self._get_subscription_id()}/resourceGroups/{self._get_resource_group()}/providers/Microsoft.Storage/storageAccounts/{storage_account_name};"
                },
                "container": {
                    "name": container_name
                },
                "dataChangeDetectionPolicy": {
                    "@odata.type": "#Microsoft.Azure.Search.HighWaterMarkChangeDetectionPolicy",
                    "highWaterMarkColumnName": "metadata_storage_last_modified"
                }
            }
            
            # DataSource ã‚’ä½œæˆã¾ãŸã¯æ›´æ–°
            response = requests.put(data_source_url, headers=headers, json=data_source_payload)
            if response.status_code in [200, 201]:
                logger.info("âœ“ DataSource 'blob-documents-source' ã‚’ä½œæˆã—ã¾ã—ãŸ")
            elif response.status_code == 204:
                logger.info("âœ“ DataSource 'blob-documents-source' ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")
            else:
                logger.error(f"âŒ DataSource ä½œæˆã‚¨ãƒ©ãƒ¼: {response.status_code} - {response.text}")
                return False
            
            logger.info("ğŸ”§ Indexer ã‚’ä½œæˆä¸­...")
            
            # Indexer ä½œæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            indexer_url = f"{self.search_service_endpoint}/indexers/blob-documents-indexer?api-version={api_version}"
            indexer_payload = {
                "name": "blob-documents-indexer",
                "dataSourceName": "blob-documents-source",
                "targetIndexName": index_name,
                "schedule": {
                    "interval": "PT5M"
                },
                "parameters": {
                    "configuration": {
                        "dataToExtract": "contentAndMetadata",
                        "parsingMode": "default"
                    }
                },
                "fieldMappings": [
                    {
                        "sourceFieldName": "metadata_storage_name",
                        "targetFieldName": "filename"
                    }
                ]
            }
            
            # Indexer ã‚’ä½œæˆã¾ãŸã¯æ›´æ–°
            response = requests.put(indexer_url, headers=headers, json=indexer_payload)
            if response.status_code in [200, 201]:
                logger.info("âœ“ Indexer 'blob-documents-indexer' ã‚’ä½œæˆã—ã¾ã—ãŸ")
            elif response.status_code == 204:
                logger.info("âœ“ Indexer 'blob-documents-indexer' ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")
            else:
                logger.error(f"âŒ Indexer ä½œæˆã‚¨ãƒ©ãƒ¼: {response.status_code} - {response.text}")
                return False
            
            # Indexer ã‚’å³åº§ã«å®Ÿè¡Œ
            logger.info("ğŸš€ Indexer ã‚’å®Ÿè¡Œä¸­...")
            run_url = f"{self.search_service_endpoint}/indexers/blob-documents-indexer/run?api-version={api_version}"
            response = requests.post(run_url, headers=headers)
            if response.status_code in [200, 202]:
                logger.info("âœ“ Indexer ã®å®Ÿè¡Œã‚’é–‹å§‹ã—ã¾ã—ãŸ")
                logger.info("ğŸ“Š ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–ã«ã¯æ•°åˆ†ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™")
            else:
                logger.warning(f"âš  Indexer å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {response.status_code} - {response.text}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ DataSource/Indexer ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _get_subscription_id(self) -> str:
        """ã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³IDã‚’å–å¾—"""
        import os
        return os.getenv("AZURE_SUBSCRIPTION_ID", "68575d55-f60d-4d89-a32b-ad90af38faa6")
    
    def _get_resource_group(self) -> str:
        """ãƒªã‚½ãƒ¼ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—åã‚’å–å¾—"""
        import os
        return os.getenv("AZURE_RESOURCE_GROUP_NAME", "avatar-ai-staging-rg")


def setup_logging(verbose: bool = False) -> None:
    """
    ãƒ­ã‚®ãƒ³ã‚°ã‚’è¨­å®šã—ã¾ã™
    
    Args:
        verbose: è©³ç´°ãƒ­ã‚°ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹ã©ã†ã‹
    """
    level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(
        level=level,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    )
